# ğŸ§  Helen ML Service - Machine Learning

Servicio de Machine Learning para entrenamiento y gestiÃ³n del modelo de reconocimiento de gestos usando PyTorch.

## ğŸ“‹ DescripciÃ³n

El servicio ML de Helen se encarga de todo el ciclo de vida del modelo:
- Captura y preparaciÃ³n de datos
- Entrenamiento del modelo con PyTorch
- ValidaciÃ³n y evaluaciÃ³n
- ExportaciÃ³n para producciÃ³n

## ğŸ—ï¸ Arquitectura

```
backend/ml-service/
â”œâ”€â”€ train_solid.py           # â­ Script principal de entrenamiento (con menÃº)
â”œâ”€â”€ data_prep.py            # PreparaciÃ³n y procesamiento de datos
â”œâ”€â”€ grabarVideo.py          # Captura de gestos para dataset
â”œâ”€â”€ test_system.py          # Tests del sistema
â”œâ”€â”€ requirements.txt        # Dependencias Python
â”œâ”€â”€ model/                  # Arquitectura del modelo
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ solid_classifier.py
â”œâ”€â”€ dataset_gestos/         # Dataset de gestos (carpetas por clase)
â”œâ”€â”€ X_data.npy             # Datos de entrenamiento procesados
â”œâ”€â”€ Y_labels.npy           # Etiquetas
â”œâ”€â”€ gestures_map.json      # Mapeo gesto â†” ID
â”œâ”€â”€ model_final.pth        # â­ Modelo entrenado
â””â”€â”€ normalization_stats.pth # EstadÃ­sticas de normalizaciÃ³n
```

## ğŸš€ Quick Start

### InstalaciÃ³n

```bash
cd backend/ml-service
python3.12 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Uso del MenÃº Interactivo

```bash
python train_solid.py
```

**Opciones del menÃº:**
1. ğŸ‹ï¸ Entrenar modelo con gestos actuales
2. â• Agregar NUEVO gesto al dataset
3. ğŸ“¹ Agregar MÃS VIDEOS a gesto existente
4. âŒ Salir

## ğŸ“š DocumentaciÃ³n Adicional

- **[Data Preparation](./data-preparation.md)** - Captura y preparaciÃ³n de datos
- **[Training](./training.md)** - GuÃ­a completa de entrenamiento
- **[Model Architecture](./model-architecture.md)** - Arquitectura del modelo

## ğŸ¯ Flujo de Trabajo TÃ­pico

### 1. Crear Nuevo Gesto

```bash
# OpciÃ³n A: MenÃº interactivo
python train_solid.py
# â†’ OpciÃ³n 2: Agregar NUEVO gesto

# OpciÃ³n B: LÃ­nea de comandos
python grabarVideo.py <nombre_gesto> ../dataset_gestos
```

### 2. Procesar Datos

```bash
# Se ejecuta automÃ¡ticamente al salir del menÃº
# O manualmente:
python data_prep.py --dataset ../dataset_gestos --output . --seq-length 40
```

### 3. Entrenar Modelo

```bash
python train_solid.py
# â†’ OpciÃ³n 1: Entrenar modelo
```

### 4. Validar Sistema

```bash
python test_system.py
```

### 5. Copiar a API

```bash
cp model_final.pth ../api/
cp gestures_map.json ../api/
cp normalization_stats.pth ../api/
```

## ğŸ“Š Archivos Generados

| Archivo | DescripciÃ³n | TamaÃ±o tÃ­pico |
|---------|-------------|---------------|
| `model_final.pth` | Modelo entrenado | ~5MB |
| `gestures_map.json` | Mapeo de gestos | <1KB |
| `normalization_stats.pth` | Stats de normalizaciÃ³n | <1KB |
| `X_data.npy` | Datos de entrenamiento | Variable |
| `Y_labels.npy` | Etiquetas | Variable |

## ğŸ”§ Requisitos del Sistema

### Hardware MÃ­nimo
- **CPU**: 4 cores
- **RAM**: 8GB
- **Storage**: 10GB libres

### Hardware Recomendado
- **CPU**: 8+ cores
- **RAM**: 16GB+
- **GPU**: NVIDIA con CUDA (opcional, acelera entrenamiento)

### Software
- Python 3.10+
- PyTorch 2.0+
- OpenCV 4.8+
- MediaPipe 0.10+

## ğŸ“ˆ Performance

### Tiempo de Entrenamiento

| Condiciones | Tiempo (30 Ã©pocas) |
|-------------|-------------------|
| CPU (4 cores) | 5-10 minutos |
| CPU (8 cores) | 3-5 minutos |
| GPU (CUDA) | 1-2 minutos |

### PrecisiÃ³n TÃ­pica

Con 20 videos por gesto:
- **Training Accuracy**: 95-98%
- **Validation Accuracy**: 85-95%

## ğŸ› Troubleshooting ComÃºn

### Error: "ModuleNotFoundError: torch"

```bash
cd backend/ml-service
source venv/bin/activate
pip install torch torchvision
```

### Error: "No such file: X_data.npy"

```bash
# Ejecutar preparaciÃ³n de datos
python data_prep.py --dataset ../dataset_gestos --output .
```

### Error: "Webcam not found"

```bash
# Verificar cÃ¡maras disponibles
ls /dev/video*

# Si no hay cÃ¡maras, el sistema no puede capturar gestos
# Usar videos pregrabados o conectar cÃ¡mara
```

### Bajo Validation Accuracy

- **Causa**: Dataset pequeÃ±o o desbalanceado
- **SoluciÃ³n**: Grabar mÃ¡s videos por gesto (mÃ­nimo 15, Ã³ptimo 20-25)

## ğŸ“ Mejores PrÃ¡cticas

### Captura de Datos

âœ… **DO:**
- Grabar en diferentes condiciones de iluminaciÃ³n
- Variar el fondo
- Usar diferentes velocidades
- Mantener mano centrada
- MÃ­nimo 15 videos por gesto

âŒ **DON'T:**
- Grabar todos los videos en mismo lugar
- Usar siempre misma velocidad
- Dejar mano fuera del encuadre
- Menos de 10 videos por gesto

### Entrenamiento

âœ… **DO:**
- Empezar con 30 Ã©pocas
- Monitorear validation accuracy
- Guardar checkpoints
- Probar modelo antes de desplegar

âŒ **DON'T:**
- Sobre-entrenar (overfitting)
- Ignorar validation loss
- Desplegar sin probar

## ğŸ”— Enlaces Ãštiles

- [Setup del ML Service](../../../setup/ML_SETUP.md)
- [API Documentation](../api/README.md)
- [Arquitectura del Sistema](../../architecture/system-overview.md)

---

**Ãšltima actualizaciÃ³n**: Octubre 2025  
**Mantenido por**: Equipo Helen - 5ta GeneraciÃ³n
